{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TextRank_newspaper_sentence_summarization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPK0xOyX14czjWOdI987Lic",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "xgQjvCDDri4t",
        "outputId": "a29d4233-eb58-4b37-8a85-32a402f954d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        },
        "tags": []
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Requirement already satisfied: konlpy in /home/ubuntu/anaconda3/lib/python3.8/site-packages (0.5.2)\nRequirement already satisfied: lxml>=4.1.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (4.5.2)\nRequirement already satisfied: JPype1>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (1.0.2)\nRequirement already satisfied: colorama in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (0.4.3)\nRequirement already satisfied: tweepy>=3.7.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (3.9.0)\nRequirement already satisfied: beautifulsoup4==4.6.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (4.6.0)\nRequirement already satisfied: numpy>=1.6 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from konlpy) (1.18.5)\nRequirement already satisfied: six>=1.10.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\nRequirement already satisfied: requests[socks]>=2.11.1 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (2.24.0)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\nRequirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.25.9)\nRequirement already satisfied: idna<3,>=2.5 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\nRequirement already satisfied: chardet<4,>=3.0.2 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\nRequirement already satisfied: certifi>=2017.4.17 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.6.20)\nRequirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\nRequirement already satisfied: oauthlib>=3.0.0 in /home/ubuntu/anaconda3/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8eKZ6RCruqh"
      },
      "source": [
        "from konlpy.tag import Kkma\n",
        "from konlpy.tag import Okt\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.preprocessing import normalize\n",
        "import numpy as np"
      ],
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ti87AZl4sNT4",
        "outputId": "bb9313ef-55a3-406c-ed12-15d939ee7f64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "tags": []
      },
      "source": [
        "kkma = Kkma()\n",
        "print(kkma.pos(\"안녕하세요? 오늘 날씨가 참 좋네요.\"))"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[('안녕', 'NNG'), ('하', 'XSV'), ('세요', 'EFN'), ('?', 'SF'), ('오늘', 'NNG'), ('날씨', 'NNG'), ('가', 'JKS'), ('참', 'MAG'), ('좋', 'VA'), ('네요', 'EFN'), ('.', 'SF')]\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K5RL7kWCsYUc"
      },
      "source": [
        "class SentenceTokenizer(object):\n",
        "  def __init__(self):\n",
        "    self.kkma = Kkma()\n",
        "    self.okt = Okt()\n",
        "    self.stopwords = ['중인' ,'만큼', '마찬가지', '꼬집었', \"연합뉴스\", \"데일리\", \"동아일보\", \"중앙일보\", \"조선일보\", \"기자\",\"아\", \"휴\", \"아이구\", \"아이쿠\", \"아이고\", \"어\", \"나\", \"우리\", \"저희\", \"따라\", \"의해\", \"을\", \"를\", \"에\", \"의\", \"가\",]\n",
        "\n",
        "  def text2sentences(self, text):\n",
        "    sentences = self.kkma.sentences(text)\n",
        "    for idx in range(len(sentences)):\n",
        "      if len(sentences[idx]) <= 10:  # if length of current sentence is lte 10, concat next sentence with current sentence.\n",
        "        sentences[idx - 1] += (\" \" + sentences[idx])\n",
        "        sentences[idx] = \"\"\n",
        "    \n",
        "    return sentences\n",
        "  \n",
        "  def get_nouns(self, sentences):\n",
        "    nouns = []\n",
        "    for sentence in sentences:\n",
        "      if sentence is not \"\":\n",
        "        nouns.append(\" \".join([noun for noun in self.okt.nouns(str(sentence)) if noun not in self.stopwords and len(noun) > 1]))\n",
        "    \n",
        "    return nouns\n"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3pACUDfOvNNh"
      },
      "source": [
        "class GraphMatrix(object):\n",
        "  def __init__(self):\n",
        "    self.tfidf = TfidfVectorizer()\n",
        "    self.cnt_vec = CountVectorizer()\n",
        "    self.graph_sentence = []\n",
        "  \n",
        "  # 명사로 이루어진 문장을 입력받아 sklearn의 TfidfVectorizer.fit_transform을 이용하여 tfidf matrix를 만든 후 Sentence graph를 return 한다.\n",
        "  # Used in sentence summarization.\n",
        "  def build_sent_graph(self, sentence):\n",
        "    tfidf_mat = self.tfidf.fit_transform(sentence).toarray()  # Sentence-Term Matrix (derived from DTM, Document-Term Matrix)\n",
        "    self.graph_sentence = np.matmul(tfidf_mat, tfidf_mat.T)  # Correlation Matrix among sentences.\n",
        "    return self.graph_sentence\n",
        "\n",
        "  # 명사로 이루어진 문장을 입력받아 sklearn의 CountVectorizer.fit_transform을 이용하여 matrix를 만든 후 word graph와 {idx: word}형태의 dictionary를 return한다.\n",
        "  # Used in keyword extraction.\n",
        "  def build_words_graph(self, sentence):\n",
        "    cnt_vec_mat = normalize(self.cnt_vec.fit_transform(sentence).toarray().astype(float), axis=0)\n",
        "    vocab = self.cnt_vec.vocabulary_\n",
        "    return np.matmul(cnt_vec_mat.T, cnt_vec_mat), {vocab[word] : word for word in vocab}\n"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9sYMnNV3z8w"
      },
      "source": [
        "# TODO: Understand this math stuffs...\n",
        "class Rank(object):\n",
        "  def get_ranks(self, graph, d=0.85):  # input: Sentence-Term Matrix (square matrix)\n",
        "    A = graph\n",
        "    matrix_size = A.shape[0]\n",
        "    for id in range(matrix_size):\n",
        "      A[id, id] = 0  # make diagonal element to zero\n",
        "      link_sum = np.sum(A[:, id])  # A[:, id] means id-th column vector\n",
        "      if link_sum != 0:\n",
        "        A[:, id] /= link_sum\n",
        "      A[:, id] *= -d\n",
        "      A[id, id] = 1\n",
        "\n",
        "    B = (1 - d) * np.ones((matrix_size, 1))\n",
        "    ranks = np.linalg.solve(A, B)  # 연립방정식 Ax = B\n",
        "    return {idx: r[0] for idx, r in enumerate(ranks)}\n"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7bFUmUU4VOF"
      },
      "source": [
        "class TextRank(object):\n",
        "  def __init__(self, text):\n",
        "    self.sent_tokenize = SentenceTokenizer()  # What we've created\n",
        "    self.sentences = self.sent_tokenize.text2sentences(text)\n",
        "    self.nouns = self.sent_tokenize.get_nouns(self.sentences)\n",
        "\n",
        "    self.graph_matrix = GraphMatrix()  # Also what we've created\n",
        "    self.sent_graph = self.graph_matrix.build_sent_graph(self.nouns)  # Build sentence graph (adjacency matrix) with given nouns\n",
        "    self.words_graph, self.idx2word = self.graph_matrix.build_words_graph(self.nouns)  # Build words graph(?) with given nouns\n",
        "\n",
        "    self.rank = Rank()  # Also what we've created\n",
        "    self.sent_rank_idx = self.rank.get_ranks(self.sent_graph)\n",
        "    self.sorted_sent_rank_idx = sorted(self.sent_rank_idx, key=lambda k: self.sent_rank_idx[k], reverse=True)\n",
        "    self.word_rank_idx = self.rank.get_ranks(self.words_graph)\n",
        "    self.sorted_word_rank_idx = sorted(self.word_rank_idx, key=lambda k: self.word_rank_idx[k], reverse=True)\n",
        "\n",
        "  def summarize(self, sent_num=3):\n",
        "    summary = []\n",
        "    index = []\n",
        "    for idx in self.sorted_sent_rank_idx[:sent_num]:\n",
        "      index.append(idx)\n",
        "    index.sort()\n",
        "\n",
        "    for idx in index:\n",
        "      summary.append(self.sentences[idx])\n",
        "\n",
        "    return summary\n",
        "\n",
        "  def keywords(self, word_num=10):\n",
        "    keywords = []\n",
        "    index = []\n",
        "    for idx in self.sorted_word_rank_idx[:word_num]:\n",
        "      index.append(idx)\n",
        "    \n",
        "    for idx in index:\n",
        "      keywords.append(self.idx2word[idx])\n",
        "\n",
        "    return keywords\n",
        "  "
      ],
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3o1PVAfNJaW5",
        "outputId": "c3ecc1ff-f68c-4400-dece-118941cb11b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 137
        },
        "tags": []
      },
      "source": [
        "text = \"\"\"\n",
        "아들의 군 휴가 특혜 의혹과 관련해 검찰로부터 무혐의 처분을 받은 추미애 법무부 장관이 30일 \"제보자의 일방적인 주장을 검증하지 않고 단지 정쟁의 도구로 삼은 무책임한 세력들은 반드시 엄중한 책임을 져야 한다\"며 경고하고 나섰다. 이에 국민의힘은 \"적반하장에 기가 찰 노릇\"이라며 반박했다.\n",
        "추 장관이 이날 오전 8시쯤 페이스북에 국민에게 사과의 뜻을 밝히면서도 야권과 언론을 향해 유감을 표명했다. 검찰의 무혐의 처분 이후 이틀 만에 반격에 나선 것이다.\n",
        "추 장관은 아들 서모씨(27)의 군 휴가 특혜 관련 의혹에 대해 \"정치공세의 성격이 짙은 무리한 고소·고발로 국론을 분열시키고 국력을 소모한 사건\"으로 규정하고, \"무책임한 세력들은 반드시 엄중한 책임을 져야 할 것이다. 합당한 사과가 없을 시 후속 조치를 취하겠다\"고 경고했다.\n",
        "언론을 향해서도 \"보도 양태에 깊은 유감을 보내지 않을 수 없다\"며 \"사실과 진실을 짚는 대신 허위의 주장을 그대로 싣고 나아가 허위를 사실인 양 보도한 다수 언론은 국민에게 커다란 실망과 상처를 줬다\"고 말했다.\n",
        "'무책임한 세력'이 누구인지는 직접 밝히진 않았지만 국민의힘 등 야권과 보수 언론을 겨냥한 것으로 풀이된다.\n",
        "이에 장제원 국민의힘 의원은 자신의 페이스북에 \"'방귀 낀 X이 성낸다'라는 말이 있다. 추 장관의 적반하장에 기가 찰 노릇\"이라고 밝혔다.\n",
        "장 의원은 이어 \"추 장관이 수사 관련 자료가 공개돼 자신의 거짓말이 탄로가 나자, 사과는 커녕 국민과 언론을 향해 겁박까지 하고 나섰다\"고 지적했다.\n",
        "장 의원은 또 \"'반드시 엄중한 책임을 져야 한다' 라구요\"라고 반문한 뒤 \"국민 앞에서 눈 하나 깜짝하지 않고 했던 거짓말부터 엄중한 책임을 져야 할 것\"이라고 반박했다.\n",
        "그러면서 \"추 장관은 '합당한 사과가 없을 시 후속 조치를 취할 것' 이라며 협박도 서슴지 않는다\"며 \"저희들이 하고 싶은 말이고, 추 장관이 했던 거짓말에 대해 합당한 사과가 없을 시, 국민과 함께 후속조치를 취해 나갈 것\"이라고 경고했다.\n",
        "국민의힘 서울 송파병 당협위원장을 맡고 있는 김근식 경남대 교수도 이날 페이스북에 \"추 장관님이 국민에게 거짓말한 것부터 사과해야 한다\"며 \"먼저 죄없는 젊은이를 거짓말쟁이로 낙인찍은 것을 사과해야 한다\"고 지적했다.\n",
        "또 추 장관이 '검찰개혁 완수'를 언급한 것과 관련해선 \"제발 이제는 검찰개혁이란 말 좀 그만하라\"며 \"국민들은 이제 검찰개혁이라 쓰고 '검찰 길들이기'라고 읽는다\"고 덧붙였다.\n",
        "안혜진 국민의당 논평에서 \"부정과 부조리, 비상식적인 짓을 해도 내 편이기만 하면 무조건 보호받는 나라가 대통령께서 꿈꾸었던 나라는 아닐 것\"이라고 말했다.\n",
        "\"\"\"\n"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GK6Gi8YnPBBi",
        "outputId": "7546d364-9061-4389-cc4d-acb79d8984ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "tags": []
      },
      "source": [
        "textrank = TextRank(text)\n",
        "for row in textrank.summarize():\n",
        "  print(row)\n",
        "  print()"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sentences: 16\n{0: 1.2178450536874006, 1: 1.197945642521139, 2: 1.4907170446522873, 3: 0.5133626257077996, 4: 0.8120908075568104, 5: 0.9612159874954654, 6: 0.5648444032592947, 7: 0.7651621670314758, 8: 0.9824053769409818, 9: 1.0385993594959444, 10: 1.5431020600697003, 11: 1.0335736292366535, 12: 1.575401350650703, 13: 1.2421385465552546, 14: 0.7589584284914123, 15: 0.30263751664767585}\n추 장관이 이날 오전 8시 쯤 페이스 북에 국민에게 사과의 뜻을 밝히면서도 야권과 언론을 향해 유감을 표명했다.\n\n장 의원은 이어 \" 추 장관이 수사 관련 자료가 공개돼 자신의 거짓말이 탄로가 나자, 사과는커녕 국민과 언론을 향해 겁 박까지 하고 나섰다\" 고 지적했다.\n\n그러면서 \" 추 장관은 ' 합당한 사과가 없을 시 후속 조치를 취할 것' 이라며 협박도 서슴지 않는다 \"며 \" 저희들이 하고 싶은 말이고, 추 장관이 했던 거짓말에 대해 합당한 사과가 없을 시, 국민과 함께 후속조치를 취해 나갈 것\" 이라고 경고했다.\n\n"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YC9JvB2oVdBy"
      },
      "source": [
        "textrank.keywords()"
      ],
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['국민', '장관', '관련', '세력', '반드시', '의혹', '특혜', '아들', '휴가', '거짓말']"
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 120,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "사회주의란 말은 다음 다섯 가지의 각기 다른 뜻으로 사용되고 있다.\n",
        "① 생산수단의 사회적 소유와 계획경제 제도를 수단으로, 자유·평등·사회정의를 실현할 것을 주장하는 사상과 운동을 뜻하는 경우(고전적 사회주의의 뜻으로 사용되는 경우)\n",
        "② 생산수단의 사회적 소유와 계획경제라고 하는 제도 자체만을 가리켜 뜻하는 경우\n",
        "③ 사회주의의 목적만을 가리키는 경우(자본주의보다 한층 훌륭한 사회를 뜻하는 경우)\n",
        "④ 공산주의의 첫째 단계 또는 보다 낮은 단계를 뜻하는 경우(공산주의자 특유의 반논리적 용법)\n",
        "⑤ 민주사회주의적 용법(민주주의적 방법에 의하여 민주주의 자체를 완성함으로써 사회를 개조하려는 사상 및 운동 또는 민주주의의 최고의 형태를 뜻하는 경우) 등이다.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sentences: 2\n"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": "['사회주의', '사용', '개조', '계획경제', '공산주의', '전적', '형태', '민주', '사상', '생산']"
          },
          "metadata": {},
          "execution_count": 121
        }
      ],
      "source": [
        "textrank = TextRank(text)\n",
        "textrank.keywords()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 122,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"\"\"\n",
        "미안하다 이거 보여주려고 어그로끌었다. 나루토 사스케 싸움수준 ㄹㅇ실화냐? 진짜 세계관최강자들의 싸움이다. 그찐따같던 나루토가 맞나? 진짜 나루토는 전설이다.진짜옛날에 맨날나루토봘는데 왕같은존재인 호카게 되서 세계최강 전설적인 영웅이된나루토보면 진짜내가다 감격스럽고 나루토 노래부터 명장면까지 가슴울리는장면들이 뇌리에 스치면서 가슴이 웅장해진다. 그리고 극장판 에 카카시앞에 운석날라오는 거대한 걸 사스케가 갑자기 순식간에 나타나서 부숴버리곤 개간지나게 나루토가 없다면 마을을 지킬 자는 나밖에 없다 라며 바람처럼 사라진장면은 진짜 나루토처음부터 본사람이면 안울수가없더라 진짜 너무 감격스럽고 보루토를 최근에 알았는데 미안하다. 지금20화보는데 진짜 나루토세대나와서 너무 감격스럽고 모두어엿하게 큰거보니 내가 다 뭔가 알수없는 추억이라해야되나 그런감정이 이상하게 얽혀있다. 시노는 말이많아진거같다 좋은선생이고.그리고 보루토왜욕하냐 귀여운데 나루토를보는것같다 성격도 닮았어 그리고버루토에 나루토사스케 둘이싸워도 이기는 신같은존재 나온다는게 사실임?? 그리고인터닛에 쳐봣는디 이거 ㄹㅇㄹㅇ 진짜팩트냐? 저적이 보루토에 나오는 신급괴물임?ㅡ 나루토사스케 합체한거봐라 진짜 ㅆㅂ 이거보고 개충격먹어가지고 와 소리 저절로 나오더라 ;; 진짜 저건 개오지는데. 저게 ㄹㅇ이면 진짜 꼭봐야돼 진짜 세계도 파괴시키는거아니야 . 와 진짜 나루토사스케가 저렇게 되다니 진짜 눈물나려고했다. 버루토그라서 계속보는중인데 저거 ㄹㅇ이냐? 하. ㅆㅂ 사스케 보고싶다.  진짜언제 이렇게 신급 최강들이 되었을까 옛날생각나고 나 중딩때생각나고 뭔가 슬프기도하고 좋기도하고 감격도하고 여러가지감정이 복잡하네. 아무튼 나루토는 진짜 애니중최거명작임.\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 123,
      "metadata": {
        "tags": []
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "sentences: 21\n{0: 0.15000000000000002, 1: 0.8890177446700036, 2: 0.8185316196212881, 3: 1.3499126050980332, 4: 1.427837982780868, 5: 1.3098376119669564, 6: 0.8687003663060708, 7: 1.0016115427174286, 8: 0.9248944391789735, 9: 0.35780615907244273, 10: 0.744214765867907, 11: 1.2802802079277806, 12: 1.1589040402487476, 13: 1.039727920730503, 14: 2.0536870657586745, 15: 1.4725032943752552, 16: 0.23996879435436863, 17: 0.6301549511198041, 18: 0.798873346622736, 19: 0.3607472936793264, 20: 1.2727882479028334}\n진짜 나루토는 전설이다.\n\n와 진짜 나루토 사스케가 저렇게 되다니\n\n진짜 눈물나려고 했다.\n\n"
        }
      ],
      "source": [
        "textrank = TextRank(text)\n",
        "for row in textrank.summarize():\n",
        "  print(row)\n",
        "  print()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ]
}